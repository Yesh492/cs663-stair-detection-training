{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ğŸš€ StairVision Enhanced Training - 300 Epochs\n",
    "\n",
    "## Improvements Over Previous Version:\n",
    "- **300 epochs** (3x more training)\n",
    "- **YOLOv8s** (small model - more accurate)\n",
    "- **Enhanced augmentation** (stronger generalization)\n",
    "- **Extended patience** (50 epochs)\n",
    "- **Better validation**\n",
    "\n",
    "**Expected Results:**\n",
    "- mAP@50: 98-99% (vs 97% current)\n",
    "- Fewer false positives\n",
    "- Better detection at various angles\n",
    "- Training Time: 3-4 hours on Colab T4 GPU"
   ],
   "metadata": {
    "id": "view-in-github"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ“¦ Cell 1: Mount Google Drive & Install Dependencies"
   ],
   "metadata": {
    "id": "setup"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install Ultralytics (YOLOv8)\n",
    "%pip install ultralytics --quiet\n",
    "\n",
    "# Import libraries\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ“ Cell 2: Dataset Preparation\n",
    "\n",
    "Upload your stair dataset to Google Drive, then update the path below."
   ],
   "metadata": {
    "id": "data"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# IMPORTANT: Update this path to your dataset location in Google Drive\n",
    "DATASET_PATH = '/content/drive/MyDrive/RGB-D stair dataset'\n",
    "\n",
    "# Copy dataset to Colab local storage for faster access\n",
    "!mkdir -p /content/stairs_dataset\n",
    "!cp -r \"{DATASET_PATH}/train\" /content/stairs_dataset/\n",
    "!cp -r \"{DATASET_PATH}/val\" /content/stairs_dataset/\n",
    "!cp -r \"{DATASET_PATH}/test\" /content/stairs_dataset/\n",
    "\n",
    "print(\"âœ… Dataset copied to local storage\")\n",
    "\n",
    "# Verify dataset structure\n",
    "!ls -lh /content/stairs_dataset/"
   ],
   "metadata": {
    "id": "copy_data"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ“‹ Cell 3: Create data.yaml Configuration"
   ],
   "metadata": {
    "id": "yaml"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create YAML configuration file\n",
    "yaml_content = \"\"\"\n",
    "# StairVision Dataset Configuration\n",
    "path: /content/stairs_dataset\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: stairs\n",
    "\"\"\"\n",
    "\n",
    "with open('/content/stairs_dataset/data.yaml', 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"âœ… data.yaml created\")\n",
    "!cat /content/stairs_dataset/data.yaml"
   ],
   "metadata": {
    "id": "yaml_create"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ¯ Cell 4: Enhanced Training - 300 Epochs"
   ],
   "metadata": {
    "id": "train"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize YOLOv8s (small model - more accurate than nano)\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# ENHANCED TRAINING - 300 EPOCHS\n",
    "results = model.train(\n",
    "    data='/content/stairs_dataset/data.yaml',\n",
    "    \n",
    "    # Training duration\n",
    "    epochs=300,              # 3x more training!\n",
    "    patience=50,             # Wait 50 epochs before early stopping\n",
    "    \n",
    "    # Model configuration\n",
    "    imgsz=640,              # Image size\n",
    "    batch=16,               # Batch size (adjust if OOM)\n",
    "    device=0,               # GPU\n",
    "    \n",
    "    # Output configuration\n",
    "    project='stair_detection_v2',\n",
    "    name='yolov8s_300epochs',\n",
    "    save=True,\n",
    "    plots=True,\n",
    "    \n",
    "    # Single class detection\n",
    "    single_cls=True,\n",
    "    exist_ok=True,\n",
    "    \n",
    "    # ENHANCED DATA AUGMENTATION\n",
    "    hsv_h=0.03,             # Hue augmentation (increased)\n",
    "    hsv_s=0.9,              # Saturation augmentation (increased)\n",
    "    hsv_v=0.6,              # Value augmentation (increased)\n",
    "    degrees=20,             # Rotation degrees (increased)\n",
    "    translate=0.2,          # Translation\n",
    "    scale=0.9,              # Scaling (increased range)\n",
    "    shear=5.0,              # Shear transformation\n",
    "    perspective=0.001,      # Perspective transformation\n",
    "    flipud=0.0,             # Vertical flip (stairs don't flip)\n",
    "    fliplr=0.5,             # Horizontal flip\n",
    "    mosaic=1.0,             # Mosaic augmentation\n",
    "    mixup=0.3,              # Mixup augmentation (increased)\n",
    "    copy_paste=0.2,         # Copy-paste augmentation\n",
    "    \n",
    "    # Optimization\n",
    "    optimizer='AdamW',      # Better optimizer\n",
    "    lr0=0.001,              # Initial learning rate\n",
    "    lrf=0.01,               # Final learning rate\n",
    "    momentum=0.95,          # Momentum\n",
    "    weight_decay=0.0005,    # Weight decay\n",
    "    warmup_epochs=5,        # Warmup epochs\n",
    "    warmup_momentum=0.8,    # Warmup momentum\n",
    "    \n",
    "    # Loss weights\n",
    "    box=7.5,                # Box loss weight\n",
    "    cls=0.5,                # Classification loss weight\n",
    "    dfl=1.5,                # Distribution focal loss weight\n",
    "    \n",
    "    # Validation\n",
    "    val=True,               # Validate during training\n",
    "    save_period=25,         # Save checkpoint every 25 epochs\n",
    "    \n",
    "    # Performance\n",
    "    cache=True,             # Cache images for faster training\n",
    "    workers=8,              # Number of workers\n",
    "    verbose=True,           # Verbose output\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ‰ Training Complete!\")\n",
    "print(f\"Results saved to: {results.save_dir}\")"
   ],
   "metadata": {
    "id": "train_model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ“Š Cell 5: View Training Results"
   ],
   "metadata": {
    "id": "results"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Display training curves\n",
    "print(\"ğŸ“ˆ Training Curves:\")\n",
    "display(Image(filename=f'{results.save_dir}/results.png'))\n",
    "\n",
    "print(\"\\nğŸ“‰ Confusion Matrix:\")\n",
    "display(Image(filename=f'{results.save_dir}/confusion_matrix.png'))\n",
    "\n",
    "print(\"\\nğŸ¯ Validation Batch Predictions:\")\n",
    "display(Image(filename=f'{results.save_dir}/val_batch0_pred.jpg'))"
   ],
   "metadata": {
    "id": "show_results"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## âœ… Cell 6: Validate Model Performance"
   ],
   "metadata": {
    "id": "validate"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Validate on test set\n",
    "metrics = model.val(data='/content/stairs_dataset/data.yaml', split='test')\n",
    "\n",
    "print(\"\\nğŸ“Š Final Model Performance:\")\n",
    "print(f\"mAP@50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP@50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "\n",
    "if metrics.box.map50 > 0.98:\n",
    "    print(\"\\nğŸ‰ EXCELLENT! Model achieved >98% mAP@50\")\n",
    "elif metrics.box.map50 > 0.95:\n",
    "    print(\"\\nâœ… GOOD! Model achieved >95% mAP@50\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Model may need more training or data\")"
   ],
   "metadata": {
    "id": "validate_model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ“± Cell 7: Export to TensorFlowLite (Float32)"
   ],
   "metadata": {
    "id": "export"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Export best model to TFLite format\n",
    "best_model = YOLO(f'{results.save_dir}/weights/best.pt')\n",
    "\n",
    "# Export to TFLite (Float32 for Android)\n",
    "tflite_path = best_model.export(\n",
    "    format='tflite',\n",
    "    imgsz=640,\n",
    "    int8=False,  # Float32 model (more accurate)\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… TFLite model exported to: {tflite_path}\")\n",
    "\n",
    "# Copy to Google Drive\n",
    "output_name = 'stair_yolo_v2_300epochs_float32.tflite'\n",
    "drive_path = f'/content/drive/MyDrive/{output_name}'\n",
    "!cp \"{tflite_path}\" \"{drive_path}\"\n",
    "\n",
    "print(f\"\\nğŸ“¥ Model saved to Google Drive: {output_name}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Download this file from Google Drive\")\n",
    "print(\"2. Place in: StairVision/app/src/main/assets/\")\n",
    "print(\"3. Update YoloDetector.kt MODEL_NAME if needed\")\n",
    "print(\"4. Build and test!\")"
   ],
   "metadata": {
    "id": "export_tflite"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ§ª Cell 8: Test on Sample Images"
   ],
   "metadata": {
    "id": "test"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Test on validation images\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Get some test images\n",
    "test_images = glob.glob('/content/stairs_dataset/val/images/*.jpg')[:5]\n",
    "\n",
    "print(f\"Testing on {len(test_images)} sample images...\\n\")\n",
    "\n",
    "for img_path in test_images:\n",
    "    results = best_model.predict(\n",
    "        source=img_path,\n",
    "        conf=0.85,  # Use your threshold\n",
    "        save=True,\n",
    "        project='test_predictions',\n",
    "        name='samples'\n",
    "    )\n",
    "    \n",
    "    # Print detection info\n",
    "    img_name = Path(img_path).name\n",
    "    if len(results[0].boxes) > 0:\n",
    "        max_conf = max([box.conf.item() for box in results[0].boxes])\n",
    "        print(f\"âœ… {img_name}: Detected stairs (conf: {max_conf:.3f})\")\n",
    "    else:\n",
    "        print(f\"âšª {img_name}: No stairs detected\")\n",
    "\n",
    "print(\"\\nğŸ“ Predictions saved to: test_predictions/samples/\")"
   ],
   "metadata": {
    "id": "test_samples"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ’¾ Cell 9: Save All Files to Google Drive"
   ],
   "metadata": {
    "id": "save"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create backup folder in Google Drive\n",
    "backup_folder = '/content/drive/MyDrive/StairVision_v2_300epochs_backup'\n",
    "!mkdir -p \"{backup_folder}\"\n",
    "\n",
    "# Copy all training results\n",
    "!cp -r \"{results.save_dir}\" \"{backup_folder}/training_results\"\n",
    "\n",
    "# Copy test predictions\n",
    "!cp -r test_predictions \"{backup_folder}/test_predictions\"\n",
    "\n",
    "print(\"âœ… All training results backed up to Google Drive\")\n",
    "print(f\"Location: {backup_folder}\")\n",
    "print(\"\\nğŸ“¦ Contents:\")\n",
    "!ls -lh \"{backup_folder}\""
   ],
   "metadata": {
    "id": "backup"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ“ˆ Cell 10: Performance Comparison"
   ],
   "metadata": {
    "id": "compare"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"ğŸ“Š Expected Improvements:\")\n",
    "print(\"\\nPrevious Model (100 epochs, YOLOv8n):\")\n",
    "print(\"  - mAP@50: ~97%\")\n",
    "print(\"  - False positives: Moderate\")\n",
    "print(\"  - Model size: 6MB\")\n",
    "print(\"\\nNew Model (300 epochs, YOLOv8s):\")\n",
    "print(\"  - mAP@50: ~98-99%\")\n",
    "print(\"  - False positives: Minimal\")\n",
    "print(\"  - Model size: ~22MB\")\n",
    "print(\"  - Better generalization\")\n",
    "print(\"  - More robust to lighting/angles\")\n",
    "print(\"\\nâœ… Recommended threshold: 0.75-0.85\")"
   ],
   "metadata": {
    "id": "comparison"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
